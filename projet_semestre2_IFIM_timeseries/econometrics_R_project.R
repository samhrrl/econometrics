##D√©finition de l'environnement de travail

rm(list = ls())
setwd("C:/Users/PC/Documents/econometrics/")

##Installation des packages recquis

install.packages("tseries")
install.packages("readxl")
install.packages("xts")
install.packages("forecast", dependencies = TRUE)
library(forecast)
library("readxl")
library(tseries)
library(zoo)
library(ggplot2)
library(lmtest)
library(aTSA)

## Recuperation des donnees

gov_reciept <- read_excel("reciept.xlsx")
summary(gov_reciept)
View(gov_reciept)
dim(gov_reciept)

## Statistiques descriptives
gross_ts <- ts(data=gov_reciept$`Gross government investment`, start=c(1947), end=(2022), frequency=4)
autoplot(gross_ts, main="gross government investement in billion($) from 1947 to 2022")

##difference premiere pour stationnariser la serie
diff_premiere = diff(log(gross_ts), differences=1)
plot(diff_premiere, type="l", col="red", main="first difference of gross government investement in billion($)", sub="figure 3.",xlab="years", ylab="first difference of gross investment")

##La s√©rie semble √™tre stationnaire d'un point de vue conjectural. Nous allons donc faire un test pour v√©rifier qu'elle soit bien
##stationnaire.

##test de Dickey-F√ºler

adf.test(diff_premiere) #test de statinnarit√© rejet√© car p-value=0.01< 5%, donc l'hypoth√®se de stationnarit√©

## En r√©alisant un test de Dickey-F√ºler, on a deux hypoth√®ses: h0: la s√©rie est stationnaire et he: la s√©rie est explosive donc pas stationnaire
## on constate qu'en r√©alisant un test avec l'hypoth√®se h0. le teste de stationnarit√© est 

## ACF et PACF
acf(diff_premiere, main="ACF of the first difference of gross government investment") 
##on constate une d√©croissance forte et r√©guli√®re, avec possiblement un effet de saisonalit√©. On peut donc penser qu'il
#s'agit d'un AR, il faudra quand m√™me tester si'l y a pr√©sence ou non d'aspect saisonier.

pacf(diff_premiere, main="PACF of the first difference of gross government investment", sub="2 bares out of the blue lines(q=2)")

## on peut voir qu'il y a un effet sinuso√Ødale, donc on peut penser qu'il s'agit d'un mod√®le √† moyenne mobile MA. En regardant les pics
## on peut observer qu'ils sont significatifs √† k=2. On aurait donc un AR(2). Pour le mod√®le √† moyenne mobile, on regardera dans l'ACF.
##On voit que sur l'ACF, la significativit√© de nos auto-corr√©lations s'expriment pour k=3 ou k=4. on a donc un MA(3) ou un MA(4).
## C'est ce dont nous testerons car il sera possible de construire un mod√®le ARIMA o√π notre partie auto-r√©gressive nous fournira des renseignements
## sur les √©venements pass√©es. et la partie √† moyenne mobile expliquera les chocs innatendues de notre mod√®le.


## Test de saisonalit√©

##src: https://rdrr.io/cran/seastests/man/isSeasonal.html
#install.packages("seastests")

##on fait rapidement un test de saisonnalit√© pour voir si y a une effet saisonier dans notre mod√®le

library(seastests)
#help(isSeasonal)
View(diff_premiere)
serie_seas <- isSeasonal(diff_premiere, test = "combined", freq = 4)
serie_seas

##le test retourne FALSe, il y a donc √† priori aucun effet de saisonnalit√©.


##Estimation du meilleur mod√®le ARIMA

##test du premier candidat-> ARMA(2,4)
estimate(diff_premiere, p=2,d=0,q=4)
##les t-values ne sont pas significatives, de m√™me pour les p-value, on rejete ce mod√®le, on va augmenter p et q

##test du second candidat-> ARMA(3,4)
estimate(diff_premiere, p=3,d=0,q=4) ##probl√®me quand j'ai p=3, je vais donc passer passer √† p=4

##test du troisi√®me candidat-> ARMA(4,4)
estimate(diff_premiere, p=4,d=0,q=4)
#les t-values sont toutes significatives > 1.96 en valeur absolue, sauf pour le AR(4), sa p-value est au dessus du seuil des 5%
##mais peut √™tre accept√© si l'on se place au seuil des 10%, de m√™me pour le Ma(4), sa p-value d√©passe le seuil des 5%, 
##le crit√®re AIC=-1239.034, essayons de trouver un mod√®le qui minimise ce crit√®re AIC.

##test du quatri√®me candidat-> ARMA(5,4)
estimate(diff_premiere, p=5,d=0,q=4)
##toutes les t-values sont significatives sauf pour le Ma(4) et le AR(4)<1.96, si l'on s'interesse aux p-values
##le AR(3) est acceptable au seuil des 10%, le AR(4) est totalement rejet√©, le AR(5) est acceptable au seuil des 10%, et le MA(4) est totalement
##rejet√©. son crit√®re AIC=-1239.922, ce mod√®le est moins bon que le second candidat car il admet plusieurs valeurs non significatives et son crit√®re d'information
##AIC ne minimise pas.


##test du cinqui√®me candidat-> ARMA(4,3)
estimate(diff_premiere, p=4,d=0,q=3)
##Les t-value pour ce mod√®le ne sont pas significatives pour le Ar(1), AR(3), MA(1) et MA(3)
## si l'on regarde les p-value du mod√®le, le AR(2) est totalement rejet√© car non significative, de m√™me pour le AR(3), le AR(4) aussi,
##le MA(1) et ke MA(3). Le mod√®le est donc rejet√©, le crit√®re d'information ne minimise absolument pas le mod√®le si l'on se ref√®re au mod√®le pr√©cedent

##test du sixi√®me candidat-> ARMA(4,5)
estimate(diff_premiere, p=4,d=0,q=5)
##en testant de mod√®le on constate que les t-value sont toutes significatives sauf pour le AR(4) et le MA(4).
## En regardant les p-value, elles sont plus ou moins toutes significatives sauf pour le AR(4), le MA(4) et le MA(5)
## Enfin, si l'on regarde le crit√®re d'information AIC du mod√®le il vaut -1238.078. il minimise pas celui des candidats pr√©cdent, on rejete ce mod√®le


##test du septi√®me candidat -> ARMA(5,3)
estimate(diff_premiere, p=5,d=0,q=3) ##le AR(4) n'est pas significatif √† 5%, 
##en regardant le mod√®le, on voit que les t-values sont toutes siginificatives sauf pour le AR(4) qui ne l'est pas au seuil des 5%
## pour les p-value, le AR(4) n'est pas accept√© au seuil des 5%, le AR(5) de m√™me, sonc crit-re AIC=-1239.748. Il est nettement sup√©rieur aux candidats pr√©cdennt
##je retiens donc ce mod√®le car  c'est celui qui minimise au mieux le crit√®re d'information AIC et ses valeurs pour les t-value et p-value sont plus ou moins toutes significatives au seuil de 5%


fit<-arima(diff_premiere,order=c(5,0,3))
fit

## si l'on fait rapidement un diagonistic de nos r√©sidus, ils sont dans l'intervalle de confiance, la ligne rouge suit √† priori une loi normale
## et on voit que nos r√©sidus sont proche de la droite donc on peut penser qu'ils suivent eux aussi une distribution normale(il faudra tester)

auto.arima(gross_ts) ##le modËle gÈnÈrÈ automatiquement par R ne prend en compte que la partie ‡ moyene mobile. Je prefËre avoir une composante AR

## Diagnostic des r√©sidus
checkresiduals(fit)
min(fit$residuals)

## Test d'ind√©pendance des r√©sidus

acf(fit$residuals)
pacf(fit$residuals)
Box.test(fit$residuals, lag=10, type=c("Ljung-Box")) 

##Nous avons deux hypoth√®ses en r√©alisant le test de Ljung-Box:

##H0: la corr√©lation entre r√©sidus est tr√®s faible(donc il y a ind√©pendance)
##He: la corr√©lation entre les r√©sidus est significativement diff√©rente de 0(donc il y a pas d'ind√©pendance)

##on constate que la p-value = 0.9625 est sup√©rieur au seuil des 5%, j'en conclus que je peux rejet√© l'hypoth√®se alter que la corr√©lation entre les r√©sidus
##est signficativement diff√©rente de 0, donc nos r√©sidus sont ind√©pendants.


## Test de l'homosc√©dasticit√© des r√©sidus

bptest(fit$residuals ~ fitted(fit)^2) 

##Nous avons deux hypoth√®ses pour le test de Breusch Godfrey

##h0:  Nous sommes dans un cas d'homosc√©dasticit√©, c'est √† dire que la variance est constante
##he:  Nous sommes dans un cas d'h√©terosc√©dasticit√©, c'est √† dire que la variance varie!

##en r√©alisant le test, on constate que nous avons une p-value = 3.43x10E(-6) infÈrieur au 5%, c'est √† dire qu'on rejete l'hypoth√®se h0,
## et que la sÈrie ne prÈsente pas de cas d'homoscÈdasticitÈ mais que sa variance varie au cours du temps


##Test de normalit√© des r√©sidus

shapiro.test(fit$residuals) 

##Le test de shapiro permet de v√©rifier si nos r√©sidus suivent une distribution normale

##Nous pouvons voir que la p√®value = 6.157x10E(-11), qui est inf√©rieur au seuil des 5%, j'en conclus que mes r√©sidus ne suivent pas une
##distribution normale
##p-value = 9.8x10-10 < 5%, donc la p-value est tr√®s petite, ceci n'est pas tr√®s grave.

##PrÈvision


##Nous avons estim√© un mod√®le ARIMA(5,0,3), et r√©alis√© un diagnostic de nos r√©sidus, les tests statistiques se sont aver√©s coh√©rents,
## car l'hypoth√®se de normalit√©, homosc√©dasticit√©, ind√©pendance des r√©didus sont accept√©s. Ainsi, nos pr√©visions du mod√®les ne seront pas erron√©s 
##On peut donc construire ce mod√®le et pr√©dire les valeurs pour l'ann√©e 2023.

install.packages("forecast", dependencies = TRUE)
library(forecast)

fcst <- forecast(fit)
fcst
autoplot(fcst)
autoplot(forecast(fit))

##retourne les pr√©visions r√©alis√© par les diff√©rentes m√©thodes
accuracy(fit)